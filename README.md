# ğŸ  LeaseWise

**LeaseWise** is a full-stack, fully local AI-powered lease analysis system designed to help tenants understand residential lease agreements with clarity and confidence.

Unlike many AI demos that rely on external APIs, managed vector databases, or cloud inference, LeaseWise implements a custom Retrieval-Augmented Generation (RAG) pipeline from scratch â€” running entirely on the userâ€™s machine with zero external dependencies.

Built to demonstrate real systems-level understanding of modern LLM workflows, LeaseWise combines semantic retrieval, structured extraction, red-flag detection, and natural-language reasoning into a cohesive AI application.

---

## ğŸš€ What It Does

Upload a residential lease PDF and instantly:

- ğŸ“„ Extract structured key terms (rent, dates, deposit, utilities, notice periods)
- âš ï¸ Detect potentially tenant-unfriendly or high-risk clauses
- ğŸ§  Generate plain-language summaries
- ğŸ’¬ Ask natural-language questions grounded strictly in the lease text

All processing happens locally using open-source models.

---

## ğŸ§  Core Technical Architecture

LeaseWise does **not** use LangChain, FAISS, Chroma, or external vector database services.

Instead, it implements a custom in-memory RAG pipeline:

### 1ï¸âƒ£ PDF Processing
- Extracts raw lease text using `pdfplumber`
- Cleans and normalizes formatting artifacts

### 2ï¸âƒ£ Semantic Chunking
- Splits text into overlapping fixed-length chunks
- Preserves contextual continuity across legal sections

### 3ï¸âƒ£ Embedding Generation
- Uses `sentence-transformers` (MiniLM)
- Converts each chunk into dense vector embeddings locally

### 4ï¸âƒ£ Custom Similarity Retrieval
- Computes cosine similarity using NumPy
- Selects Top-K relevant chunks for query grounding
- Stores embeddings in memory (no vector DB)

### 5ï¸âƒ£ LLM-Orchestrated Reasoning
- Sends retrieved context to a local LLM via **Ollama** (e.g., Llama 3)
- Uses structured prompt engineering
- Enforces JSON-mode responses for deterministic extraction
- Implements timeout handling and safe response parsing

---

## ğŸ“¦ Features

### ğŸ—‚ Structured Lease Term Extraction
Extracts machine-readable fields such as:
- Monthly rent
- Lease start & end dates
- Security deposit
- Utility responsibilities
- Notice requirements

Implemented using JSON-constrained prompting with robust parsing safeguards.

---

### âš ï¸ Red Flag Clause Detection
Identifies clauses that may be:
- Excessively punitive
- Vague or ambiguous
- Potentially tenant-disadvantaging

Uses LLM-based classification with structured severity labeling.

---

### ğŸ§¾ Plain-Language Summarization
Transforms dense legal language into a concise, human-readable overview.

---

### ğŸ’¬ Context-Grounded Q&A
Users can ask:
- â€œCan the landlord enter without notice?â€
- â€œWho pays for internet?â€
- â€œWhat happens if rent is late?â€

Responses are generated strictly from retrieved lease context to reduce hallucination.

---

## ğŸ—ï¸ Tech Stack

**Frontend**
- React (Vite)
- Custom UI (no component libraries)
- Fetch-based API integration

**Backend**
- Python
- Flask
- pdfplumber
- NumPy
- sentence-transformers (MiniLM)

**LLM Runtime**
- Ollama (local LLM runtime)
- Llama 3 (or compatible open-source models)
- JSON-mode structured prompting

**Architecture Concepts**
- Retrieval-Augmented Generation (RAG)
- Semantic embeddings
- Cosine similarity search
- Context window management
- Deterministic response parsing

---

## ğŸ”’ Local-First Design Philosophy

- No OpenAI API  
- No Hugging Face inference endpoints  
- No vector database services  
- No AWS or cloud infrastructure  
- Zero API cost  
- Full document privacy  

All processing runs locally.

---

## ğŸ› ï¸ How to Run

### 1ï¸âƒ£ Backend Setup

    cd backend
    python -m venv venv

    # Windows PowerShell only:
    Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
    .\venv\Scripts\activate

    pip install -r requirements.txt
    python app.py

Backend runs at:
http://localhost:5000

---

### 2ï¸âƒ£ Install Ollama

Download from:
https://ollama.com

Pull a model:

    ollama pull llama3

Ensure Ollama is running:

    ollama list

---

### 3ï¸âƒ£ Frontend Setup

    cd frontend
    npm install
    npm run dev

Frontend runs at:
http://localhost:5173

---

## ğŸ“ˆ Why This Project Stands Out

LeaseWise demonstrates:

- Full-stack engineering (React + Flask)
- Custom RAG system implementation
- Embedding-based semantic retrieval
- Local LLM orchestration
- Structured prompt engineering
- Robust JSON parsing and error handling
- Real-world document AI application design

This is not a wrapper around an AI API â€” it is a ground-up implementation of a modern LLM-powered system.

---
